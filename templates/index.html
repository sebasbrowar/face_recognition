<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Reconocimiento Facial</title>
  <script defer src="/static/js/face-api.min.js"></script>
  <style>
    body {
      background-color: #1e1e1e;
      color: white;
      text-align: center;
      font-family: 'Segoe UI', sans-serif;
      margin: 0;
      padding: 0;
    }

    h1 {
      color: #ff8800;
      margin-top: 20px;
    }

    video, canvas {
      position: absolute;
      top: 0;
      left: 50%;
      transform: translateX(-50%);
      border: 4px solid #ff8800;
      border-radius: 12px;
      width: 100%;
      max-width: 640px;
    }

    #nombreDetectado {
      position: absolute;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      font-size: 1.5em;
      color: #ff8800;
    }
  </style>
</head>
<body>
  <h1>Reconocimiento Facial</h1>
  <video id="video" width="640" height="480" autoplay muted></video>
  <canvas id="overlay" width="640" height="480"></canvas>
  <div id="nombreDetectado">Cargando modelos...</div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const context = canvas.getContext('2d');
    const nombreDiv = document.getElementById('nombreDetectado');

    async function cargarModelos() {
      try {
        await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
        await faceapi.nets.faceRecognitionNet.loadFromUri('/models');

        nombreDiv.textContent = "Modelos cargados. Activando cámara...";
        iniciarCamara();
      } catch (error) {
        nombreDiv.textContent = "Error al cargar modelos";
        console.error("Error al cargar modelos:", error);
      }
    }

    async function iniciarCamara() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "user" },
          audio: false
        });

        video.srcObject = stream;
        video.onloadedmetadata = () => {
          video.play();
          detectarEnTiempoReal();
        };
      } catch (error) {
        nombreDiv.textContent = "Error al acceder a la cámara";
        console.error("Error de cámara:", error);
      }
    }

    async function detectarEnTiempoReal() {
      const opciones = new faceapi.TinyFaceDetectorOptions();

      setInterval(async () => {
        const detecciones = await faceapi.detectAllFaces(video, opciones)
          .withFaceLandmarks()
          .withFaceDescriptors();

        context.clearRect(0, 0, canvas.width, canvas.height);

        const resizedDetections = faceapi.resizeResults(detecciones, {
          width: canvas.width,
          height: canvas.height
        });
        faceapi.draw.drawDetections(canvas, resizedDetections);

        if (detecciones.length > 0) {
          capturarYReconocer(detecciones);
        } else {
          nombreDiv.textContent = "Detectando rostro...";
        }
      }, 100);
    }

    async function capturarYReconocer(detecciones) {
      const tempCanvas = document.createElement("canvas");
      tempCanvas.width = video.videoWidth;
      tempCanvas.height = video.videoHeight;
      const tempCtx = tempCanvas.getContext("2d");
      tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
      const dataUrl = tempCanvas.toDataURL('image/jpeg');

      try {
        const respuesta = await fetch('/reconocer', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ imagen: dataUrl })
        });
        const resultado = await respuesta.json();
        nombreDiv.textContent = `Reconocido: ${resultado.nombre}`;
      } catch {
        nombreDiv.textContent = "Error al reconocer rostro";
      }
    }

    cargarModelos();
  </script>
</body>
</html>
